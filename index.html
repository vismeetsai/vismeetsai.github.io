<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html lang="en">

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

	<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
	<link rel="icon" href="data:,">
	<link type="text/css" media="all" href="./css/style.css" rel="stylesheet">
	<title>Vis Meets AI</title>
	<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1.0, maximum-scale=1.0">
</head>

<body data-rsssl="1" class="projects-template-default single single-projects postid-49496 vsc-initialized">
	<header id="page-top">
		<div class="cols wrapper2 clearfix">
			<div class="col col2 top-container">
				<img src="./image/logo_red.png" class="logo">
			</div>
			<div class="col col2">
				<br>
				<h1>Visualization Meets AI 2025</h1>
			</div>
		</div>
	</header>
	<div class="page-outer">
		<br>
		<div class="project-entry">
			<div class="content-block page-entry default">
				<div class="cols wrapper2 clearfix">
					<div class="col col2">
						<h2>Goals</h2>
					</div>
					<div class="col col2">
						<p class="mb0">
							The task of data visualization generally involves a design step, which requires the
							knowledge of the data domain and visualization methods to do well. Because of the immense
							design space for optimization, it can take both novices and
							experts substantial effort to derive desired visualization results from data for exploration
							or communication. Following the resurgence of artificial intelligence (AI) technology in
							recent years, in the field of visualization, there is
							a growing interest and opportunity in applying AI to perform data transformation and to
							assist the generation of visualization, aiming to strike a balance between cost and quality.
							The use of visualization to enhance AI is the other
							active line of research. This workshop, held in conjunction with <a
								href="https://pacificvis2025.github.io/">IEEE&nbsp;PacificVis&nbsp;2025</a>, aims
							at exploring this emerging area of research and practice by fostering communication
							between visualization researchers and practitioners. Attendees will be introduced to the
							latest and greatest research innovations in AI-enhanced visualization (AI4VIS) as well as
							visualization-enhanced AI (VIS4AI), and also learn about further research opportunities. The
							workshop will be composed of full-paper presentations, short-paper presentations, and
							invited talks.
						</p>
					</div>
				</div>
			</div>
		</div>
		<div class="content-block page-entry gray-bgr">
			<div class="cols wrapper2 clearfix">
				<div class="col col2">
					<h2>Call for Participation</h2>
				</div>
				<div class="col2 col">
					<h3>Submission</h3>
					<p>
						We welcome contributions as full papers and short papers.
						All accepted papers will appear in the proceedings of the IEEE PacificVis 2025 and the IEEE
						Xplore Digital Library.
					</p>
					<p>
						Papers should follow the <a
							href="https://tc.computer.org/vgtc/publications/conference/">formatting guidelines for VGTC
							Conference Style Papers</a>.
						There is no strict page limit, but authors are encouraged to submit a paper whose length matches
						its contribution.
						Our recommendation for the paper length is as follows:
					</p>
					<p> - Full paper: up to 10 pages (including reference)</p>
					<p> - Short paper: up to 6 pages (including reference)</p>
					<h4></h4>
					<p>
						Both full papers and short papers are to be submitted using <a
							href="https://new.precisionconference.com/vgtc">PCS</a> (Track Name: PacificVis 2025
						Visualization Meets AI Workshop). We will accept both single-blind (not anonymized) as well as
						double-blind (anonymized) submissions. In the case of double-blind submissions, please
						substitute the author names with the paper ID number.
					</p>

					<h3>Important Dates (for both full papers and short papers)</h3>
					<p>- Paper due: December 27, 2024</p>
					<p>- 1st cycle notification: January 31, 2025</p>
					<p>- Revision due: February 14, 2025</p>
					<p>- 2nd cycle notification: February 24, 2025</p>
					<p>- Camera ready paper due: March 3, 2025</p>
					<p>- Workshop: April 22, 2025</p>
					<p>All deadlines are due at 11:59pm (23:59) Anywhere on Earth (AoE).</p>
					<br>

					<h3>Topics of Interest</h3>
					<p>
						We encourage submissions of high quality research and application papers incorporating
						visualization and AI/machine lerning. Our interest includes both topics of AI4VIS and VIS4AI.
					<p>Example papers:</p>
					<div class="paper-cate">AI4VIS</div>
					<div class="papers">P.-P. V&aacute;zquez.
						<a href="https://doi.org/10.1109/PacificVis60374.2024.00049">
							Are LLMs ready for Visualization?</a>
						In Proc. PacificVis, pp. 343-352, 2024.
					</div>
					<div class="papers">J. Han and C. Wang.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X22000213">
							VCNet: A Generative Model for Volume Completion.</a>
						Visual Informatics, 6(2): 62-73, 2022.
					</div>
					<div class="papers">L. Giovannangeli, R. Bourqui, R. Giot, and D. Auber.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X20300140">
							Toward Automatic Comparison of Visualization Techniques: Application to Graph
							Visualization.</a>
						Visual Informatics, 4(2): 86-98, 2020.
					</div>
					<!-- <div class="papers">R. Guo, T. Fujiwara, Y. Li, K. M. Lima, S. Sen, N. K. Tran, and K.-L. Ma. "<a href="https://www.sciencedirect.com/science/article/pii/S2468502X20300139">Comparative visual analytics for assessing medical records with
							sequence embedding</a>." Visual Informatics, 4(2): 2020.</div> -->
					<!-- <div class="papers">W. He, J. Wang, H. Guo, H.-W. Shen, and T. Peterka. "CECAV-DNN: Collective ensemble comparison and visualization using deep neural networks." Visual Informatics, 4(2): 2020.</div> -->
					<div class="papers">J. Shen, R. Wang, and H.-W. Shen.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X20300152">
							Visual Exploration of Latent Space for Traditional Chinese Music.</a>
						Visual Informatics, 4(2): 99-108, 2020.
					</div>
					<br />
					<div class="paper-cate">VIS4AI</div>
					<div class="papers">Z. Liang; G. Li; R. Gu; Y. Wang; G. Shan.
						<a href="https://doi.org/10.1109/PacificVis60374.2024.00051">
							SampleViz: Concept based Sampling for Policy Refinement in Deep Reinforcement Learning.</a>
						In Proc. PacificVis, pp. 359-368, 2024.
					</div>
					<!-- <div class="papers">P. Chawla, S. Hazarika, and H.-W. Shen. "Token-wise sentiment decomposition for ConvNet: Visualizing a sentiment classifier." Visual Informatics, 4(2): 2020.</div> -->
					<div class="papers">M. Gleicher, X. Yu, and Y. Chen.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X22000195">Trinary Tools for
							Continuously Valued Binary Classifiers.</a>
						Visual Informatics, 6(2): 74-86, 2022.
					</div>
					<div class="papers">X. Ji, Y. Tu, W. He, J. Wang, H.-W. Shen, and P.-Y. Yen.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X21000097">
							USEVis: Visual Analytics of Attention-Based Neural Embedding in Information Retrieval.</a>
						Visual Informatics, 5(2): 1-12, 2021.
					</div>
					<!-- <div class="papers">Y. Li, T. Fujiwara, Y. K. Choi, K. K. Kim, and K.-L. Ma. "<a href="https://www.sciencedirect.com/science/article/pii/S2468502X20300176">A visual analytics system for multi-model comparison on clinical data
							predictions</a>." Visual Informatics, 4(2): 2020.</div> -->
					<div class="papers">M. Wang, J. Wenskovitch, L. House, N. Polys, and C. North.
						<a href="https://www.sciencedirect.com/science/article/pii/S2468502X21000085">
							Bridging Cognitive Gaps between User and Model in Interactive Dimension Reduction.</a>
						Visual Informatics, 5(2): 13-25, 2021.
					</div>

					<br>
				</div>
				<br>
			</div>
		</div>
		<div class="content-block page-entry default ">
			<div class="cols wrapper2 clearfix">
				<div class="col2 col">
					<h2>People</h2>
				</div>
				<div class="col2 col">
					<h3>Workshop Chair</h3>
					<p class="people">Takanori Fujiwara, Link√∂ping University</p>
					<p class="people">Junpeng Wang, Visa Research</p>
					<br>
					<h3>Program Committee</h3>
					<p class="people">Dylan Cashman, Brandeis University</p>
					<p class="people">Angelos Chatzimparmpas, Utrecht University</p>
					<p class="people">Changjian Chen, Hunan University</p>
					<p class="people">Steffen Frey, University of Groningen</p>
					<p class="people">Jun Han, The Hong Kong University of Science and Technology</p>
					<p class="people">Subhashis Hazarika, Fujitsu Research of America</p>
					<p class="people">Dongyu Liu, University of California, Davis</p>
					<p class="people">Mengchen Liu, Microsoft Research</p>
					<p class="people">Rita Sevastjanova, ETH Zurich</p>
					<p class="people">Huan Song, Amazon AWS AI</p>
					<p class="people">Jun Tao, Sun Yat-sen University</p>
					<p class="people">Qianwen Wang, University of Minnesota</p>
					<p class="people">Yong Wang, Nanyang Technological University</p>
					<p class="people">John Wenskovitch, Pacific Northwest National Laboratory</p>
					<p class="people">Jun Yuan, Apple</p>
					<br>
				</div>
			</div>
		</div>
		<div class="content-block page-entry default no-padding-top gray-bgr" style="padding-top:0px;">
			<div class="cols wrapper2 clearfix">
				<div class="col2 col">
					<h2>Past Events</h2>
				</div>
				<div class="col2 col">
					<p><a href="./2024/index.html">Visualization Meets AI 2024</a></p>
					<p><a href="./2023/index.html">Visualization Meets AI 2023</a></p>
					<p><a href="./2022/index.html">Visualization Meets AI 2022</a></p>
					<p><a href="./2021/index.html">Visualization Meets AI 2021</a></p>
					<p><a href="./2020/index.html">Visualization Meets AI 2020</a></p>
				</div>
				<br />
			</div>
		</div>
		<div class="content-block page-entry dark">
			<div class="cols wrapper2 clearfix">
				<div class="col2 col footer-div">
					<p>&nbsp;&nbsp;</p>
				</div>
				<div class="col2 col">
					<br />
					<div class="the-block">
						<h3 class="selectionShareable">CONTACT</h3>
						<p>pvis_ai4vis@pvis.org</p>
						<br />
					</div>
				</div>
				<br>
			</div>
		</div>
	</div>
</body>

</html>